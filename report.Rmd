---
title: "Ames Iowa House Prediction Project"
author: "Jordan Kassof and Jose Torres"
date: "2/11/2018"
output:
  pdf_document:
    toc: true
  rmdformats::readthedown:
    highlight: kate
---


```{r knitr_init, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=FALSE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)

source("scripts/interp_models.R")
```


***

# Introduction

Buying a house is one of the largest financial decisions many people will make. So many factors go into someone's decision, but it can be hard to really explain why one house "felt right" and another didn't. We want to quantify the factors that add up to someone making the decision to purchase a house.

# Data Description

We will be using the Ames, Iowa individual residential property sales data set freely available on Kaggle.com.  The dataset contains 2,930 observations with 79 explanatory variables. All observations occur between 2006 and 2010. Given the geography dependent nature of home value, the results of below analyses can't be applied nationally. For more information on the data, or to download it yourself, visit https://www.kaggle.com/c/house-prices-advanced-regression-techniques.

See the codebook.txt file in the github repo for complete information about all variables.

***

# Exploratory Analysis

Comments on various things noticed as exloring the data and general idea of what the cleaning was. Reference appendix for entire cleaninf functions and scripts.

***

# Questions of Interest

We focused on two approaches, one geared towards model performance and one towards model interpretability by one of the parties involves in a home purchase.

## Interpretable Models

For the interpretable model approach, rather than just taking a handful of easily understood parameters and building a model, we wanted to take a different approach. There are many adages when it comes to home buying, we wanted to see which are the most true. The three ideas about what drives the price of a house that we looked at are as follows:

* Location, location, location!
    * For this model, we used parameters that are related to the physical location of the property. For example, neighborhood, zoning, frontage, lot size, etc.
* It's all about the curb appeal
    * For this model, we used parameters related to the external appearance of the property. For exampe, house style, roof style, external vaneer materials, etc.
* It's what's on the inside that counts
    * For this model, we used parameters related to the internals of the property, the bones if you will. For example, the foundation, the electrical and heating system, etc.
    
We also included the Sale Condition variable in all three models because the context of the sale seems like way too key of a factor to leave out of any model that is meant to be easily interpretted.



### Model Selection

After running our three models, let's take a look at some diagnostics. After picking a model based on diagnostics, we will examine assumptions and parameters.

```{r diagnostics_table}
kable(
  bind_cols(
    data.frame(ModelName = c("location", "inside", "outside")),
    bind_rows(model_diags)
    ) %>%
    select(ModelName, adj.r.squared, AIC, BIC, df)
  )
```

Based on R~2~, AIC, and BIC, the best model appears to be the location model. Let's examine some diagnostic plots to make sure the assumptions of linear regression are met.

```{r fig.width=4, fig.height=4, fig.align='center'}
plot(loc_lm$residuals, ylab = 'Residual', main = 'Constant Variance Check')
```

In the plot above, it appears there is not strong evidence against the assumption of constant variance in our residuals. I see a few points that could be concerning but we will proceed with caution for now.



```{r fig.width=4, fig.height=4, fig.align='center'}
hist(loc_lm$residuals, xlab = 'Residual', main = 'Residual Normality')
```

This histogram shows a symetric distribution, and does not provide strong evidence against normality. We will proceed with caution.


### Parameter Interpretation

Interpretation - make sure to reverse the log transpose correctly
Confidence Intervals

```{r}
td <- tidy(loc_lm, conf.int = TRUE)
library(ggplot2)
ggplot(td[-1,], aes(estimate, term, color = term)) +
    geom_point() +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
    theme(legend.position = 'none')
```

The neighborhood variable has quite a lot of levels, but we can get an idea here for all the parameters estimates and a 95% confidence interval. Let's take a closer look at the five variables with the largest coefficient estimates.

```{r}
td %>% arrange(desc(estimate)) %>% slice(2:6) %>% kable()
```

It appears that the zoning variable has a very strong effect on the price, as does the size of the lot.  

## Predictive Models

Restatement of problem here

### Model Selection

Type of Selection
Assumptions
Comparing Competing Models
    AIC, BIC, adj R2
    Interval CVPress
    External Cross Validation
    Kaggle Score
    

***

# Conclusion

# Appendix

```{r comment=''}
cat(readLines('scripts/interp_models.R'), sep = '\n')
```

```{r comment=''}
cat(readLines('scripts/cleaner_funs.R'), sep = '\n')
```

```{r comment=''}
cat(readLines('scripts/cleaner_script.R'), sep = '\n')
```

```{r comment=''}
#cat(readLines('a.csv'), sep = '\n')
```

